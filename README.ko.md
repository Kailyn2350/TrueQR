[English](README.md) | **한국어** | [日本語](README.ja.md)

---

# TrueQR: QR 코드 위조 방지 프로젝트

## 개요

이 프로젝트의 주요 목표는 원본 보안 QR 코드와 스캔 또는 복사로 생성된 위조 버전을 구별할 수 있는 로직을 개발하는 것이었습니다. 핵심 아이디어는 원본 QR 코드 이미지에 깨지기 쉬운 "암호화" 또는 디지털 워터마크를 삽입하는 것입니다. 이 워터마크는 복사 과정에서 파괴되거나 크게 변경되도록 설계되어 위조품을 탐지할 수 있게 합니다.

이 문서는 방법론, 통제된 디지털 환경에서의 성공, 그리고 물리적 매체와 카메라를 사용하는 실제 시나리오에 기술을 적용할 때 발견된 과제들을 간략하게 설명합니다.

## 핵심 개념 및 방법론

검증 프로세스는 일반적인 복사 흔적을 찾는 것이 아니라, QR 코드의 픽셀 데이터에 내장된 특정하고 깨지기 쉬운 신호의 저하를 감지하도록 설계되었습니다. 이 내장된 워터마크는 일반적인 보기에는 견딜 수 있을 만큼 충분히 튼튼하지만, 인쇄-스캔 또는 디지털-아날로그 변환 과정에 의해 파괴될 만큼 깨지기 쉽게 설계되었습니다.

### 1. 지각 해시 (Perceptual Hash, pHash)

**지각 해시(Perceptual Hash, pHash)**는 이미지의 **저주파수 성분(low-frequency components)**을 기반으로 **핑거프린트(fingerprint)**를 생성하는 방법입니다. 이 핑거프린트는 **QR 코드 구조**의 전반적인 표현을 제공하며, **약간의 크기 조정(scaling)**이나 **압축(compression)**에는 강하지만 전체적인 구조가 변경되면 값이 달라집니다. 처리 과정은 다음과 같이 나눌 수 있습니다.

#### **pHash 생성 단계:**

1. **이미지를 그레이스케일로 변환하고 크기 조정**

먼저 이미지 $I$를 **그레이스케일(grayscale)로 변환**하고 고정된 크기(예: $32 \times 32$)로 조정합니다.

> **그레이스케일(Grayscale) 변환이란?**
>
> 그레이스케일 변환은 컬러 이미지의 각 픽셀이 가진 R(Red), G(Green), B(Blue) 3채널의 색상 정보를 **단일 채널의 밝기(Luminance) 정보**로 압축하는 과정입니다. 즉, "컬러"를 "흑백 명암"으로 바꾸는 작업입니다.
>
> 널리 사용되는 변환 공식은 각 색상이 사람의 눈에 얼마나 밝게 보이는지를 가중치로 적용하며, 다음과 같습니다. 이 공식은 녹색(G)을 가장 밝게, 파란색(B)을 가장 어둡게 인식하는 인간의 시각적 특성을 반영합니다.
>
> $$\text{Grayscale} = (0.299 \times R) + (0.587 \times G) + (0.114 \times B)$$
>
> 예를 들어, `R=200, G=100, B=50` 이라는 색상 값을 가진 픽셀은 위 공식에 따라 약 `118.2` 라는 단일 밝기 값으로 변환됩니다. 이렇게 3차원의 색상 정보를 1차원의 밝기 정보로 단순화합니다.

-   이 단계는 색상 정보를 제거하여 이미지를 단순화하고, 크기를 일관되게 만들어 이후 연산(DCT)이 구조적 특징에만 집중하도록 합니다.


2. **2D 이산 코사인 변환(DCT) 적용**

그레이스케일로 변환된 이미지 $I$에 **2D DCT(이산 코사인 변환)**를 적용하여 주파수 영역의 행렬 $C$로 변환합니다.

$$C = \text{DCT}(I)$$

> **DCT(이산 코사인 변환)의 원리**
>
> DCT는 이미지의 픽셀 밝기 값을 **공간적 분포(spatial domain)**에서 **주파수 성분(frequency domain)**으로 변환하는 강력한 수학적 도구입니다. 이 과정을 이해하기 위해 먼저 기본적인 **1D DCT**부터 살펴보겠습니다.
>
> 1차원 데이터 배열(예: 이미지의 한 줄) $f(x)$에 대한 DCT 변환 $F(u)$는 다음과 같이 정의됩니다.
>
> **[ 1D DCT 공식 ]**
> 
> $$F(u) = \alpha(u) \sum_{x=0}^{N-1} f(x) \cos\left[\frac{(2x+1)u\pi}{2N}\right]$$
> 
> (이때 $\alpha(u)$는 정규화 계수로, $u=0$일 때 $\sqrt{1/N}$이고 $u>0$일 때 $\sqrt{2/N}$입니다.)
>
> **2D DCT**는 이 1D DCT를 2차원으로 확장한 것입니다. 이미지의 모든 **행**에 1D DCT를 적용하고, 그 결과로 나온 행렬의 모든 **열**에 다시 1D DCT를 적용하는 것과 동일한 결과를 냅니다. 2D DCT의 전체 공식은 다음과 같습니다.
>
> **[ 2D DCT 공식 ]**
> 
> $$F(u,v) = \alpha(u) \alpha(v) \sum_{x=0}^{N-1} \sum_{y=0}^{M-1} f(x,y) \cos\left[\frac{(2x+1)u\pi}{2N}\right] \cos\left(\frac{(2y+1)v\pi}{2M}\right)$$
>
> 이 변환을 통해 이미지를 구성하는 복잡한 시각 정보를 '느린 변화'와 '빠른 변화'를 나타내는 주파수 성분으로 분해할 수 있습니다.
>
> -   **저주파(Low-frequency):** 이미지에서 색이나 밝기가 **서서히 변하는 넓은 영역**을 의미합니다. 예를 들어, 하늘이나 벽의 부드러운 색감, 이미지의 전반적인 구조와 형태가 여기에 해당합니다.
> -   **고주파(High-frequency):** 픽셀 값이 **급격하게 변하는 부분**으로, 이미지의 세밀한 디테일, 경계선, 질감(texture), 노이즈 등을 나타냅니다.
>
> 2D DCT를 적용하면, 변환된 행렬($C$)의 **좌측 상단**에는 저주파 성분이, **우측 하단**으로 갈수록 고주파 성분이 집중됩니다. pHash는 이 중에서 이미지의 핵심 골격을 이루는 저주파 성분만을 사용하기 위해 이 변환 과정을 거칩니다.

-   **요약:** DCT는 이미지를 공간 영역에서 **주파수 영역**으로 변환하며, 이를 통해 이미지의 **저주파**(큰 구조)와 **고주파**(세부 사항) 성분을 분리할 수 있게 됩니다.

3. **저주파수 8x8 영역 추출**

앞선 2단계에서 DCT 변환을 거치면 이미지의 주파수 정보가 행렬의 위치에 따라 정렬됩니다. 이 원리를 이용하여 이미지의 핵심 구조를 나타내는 저주파수 영역을 추출합니다.

> **왜 좌측 상단이 저주파수 영역인가?**
>
> 2D DCT의 중요한 특징은 에너지 집중(Energy Compaction) 효과입니다. 대부분의 시각적 정보, 즉 에너지를 소수의 저주파수 계수(좌측 상단)에 집중시키는 성질을 가집니다.
>
> -   **좌측 상단 `C[0,0]` (DC 계수):** 이미지 블록의 **평균 밝기**를 나타내는 가장 중요한 저주파 성분입니다. 보통 가장 큰 값을 가집니다.
> -   **좌측 상단 주변:** DC 계수에서 멀어질수록(오른쪽, 아래로 갈수록) 점차 **더 높은 주파수**의 성분을 나타내며, 이 값들은 일반적으로 급격히 작아집니다.
>
> **[ 간단한 4x4 행렬의 2D DCT 예시 ]**
>
> 이해를 돕기 위해, 좌측 상단이 밝고 우측 하단이 어두운 간단한 4x4 이미지 블록의 밝기 값이 있다고 가정해 보겠습니다.
>
> **입력 밝기 값 (f(x, y))**
> 
> $$\begin{bmatrix}255 & 200 & 150 & 100 \\\\\ 200 & 150 & 100 & 50 \\\\\ 150 & 100 & 50 & 0 \\\\\ 100 & 50 & 0 & 0 \end{bmatrix}$$
>
> 이 행렬에 **2D DCT를 적용한 결과 (F(u, v))**는 다음과 같습니다. (소수점 반올림)
> 
> $$\begin{bmatrix}\mathbf{401} & \mathbf{-137} & \mathbf{27} & \mathbf{-8} & \\\\\mathbf{-137} & \mathbf{-2} & \mathbf{-8} & \mathbf{2} \\\\\mathbf{27} & \mathbf{-8} & \mathbf{2} & \mathbf{-2} \\\\\mathbf{-8} & \mathbf{2} & \mathbf{-2} & \mathbf{1}\end{bmatrix}$$
> 
> 결과를 보면, **가장 큰 에너지(값의 절대값)가 좌측 상단에 집중**되어 있고, 우측 하단으로 갈수록 값이 0에 가까워지는 것을 명확히 확인할 수 있습니다.

pHash에서는 전체 32x32 DCT 행렬 중, 이처럼 핵심 에너지가 모여있는 **좌측 상단의 8x8 영역($C_{\text{low}}$)만 사용**합니다. 이 64개의 계수는 이미지의 전반적인 구조를 표현하기에 충분하며, JPEG 압축 등에서도 널리 사용되는 효율적인 방식입니다.

-   **요약:** 추출된 8x8 저주파수 성분들은 이미지의 **전반적인 밝기**와 **핵심적인 형태**를 대표합니다.

4. **중간값 계산**

앞서 추출한 8x8 저주파 영역을 0과 1로 구성된 해시로 변환하기 위한 기준점을 설정하는 단계입니다. 8x8 행렬의 첫 번째 값인 `C[0,0]`은 이미지 블록 전체의 평균 밝기를 나타내므로, 구조적 특징을 비교하는 데에는 적합하지 않습니다. 따라서 이 값을 제외한 나머지 63개의 주파수 계수들을 사용합니다.

이 63개 값들의 대표적인 특징을 나타내는 기준점을 찾기 위해 **중간값(median)**을 계산합니다. 중간값이란 주어진 값들을 크기순으로 정렬했을 때 정확히 가운데에 위치하는 값을 의미합니다. 예를 들어, `[1, 3, 5, 7, 9]`의 5개 값이 있다면 중간값은 `5`가 됩니다.

$$m = \text{median}(C_{\text{low}}[1:, 1:]) $$

-   이렇게 계산된 중간값 `m`은 다음 단계에서 해시 비트를 0과 1로 결정하는 최종 기준선(임계값) 역할을 합니다.

**5. 63비트 해시 생성**

이 마지막 단계에서는 앞서 계산한 중간값 `m`을 기준(임계값)으로 사용하여, 이미지의 저주파수 정보를 63비트의 고유한 디지털 핑거프린트, 즉 **지각 해시(pHash)**로 변환합니다.

구체적인 과정은 다음과 같습니다. 3단계에서 추출한 8x8 저주파 영역(`C_low`)에는 총 64개의 주파수 계수가 있습니다. 이 계수들을 중간값 `m`과 하나씩 비교하여 0 또는 1로 변환합니다.

여기서 중요한 점은, 64개의 계수 중 평균 밝기인 **DC 성분(`C[0,0]`)은 이 비교 과정에서 제외된다**는 것입니다. 오직 이미지의 구조를 나타내는 63개의 AC 계수만이 해시를 구성하는 데 사용됩니다. 이것이 '64비트'가 아닌 '63비트' 해시가 생성되는 이유입니다.

각 AC 계수($c_i$)를 중간값($m$)과 비교하는 규칙은 다음과 같습니다.

$$h_i = \begin{cases} 1 & \text{if } c_i > m \\\0 & \text{otherwise}\end{cases}$$

-   **해석:** 63개의 AC 계수 각각에 대해, 그 값이 중간값 `m`보다 **크면 1**, 작거나 같으면 **0**을 할당합니다.

> **[ 간단한 해시 생성 예시 ]**
>
> 만약 63개 AC 계수 중 첫 5개가 `[15.3, -20.1, 5.5, 30.9, -2.0]`이고, 4단계에서 계산된 중간값 `m`이 `4.5`라고 가정해 보겠습니다.
>
> 각 계수를 `m`과 비교한 결과는 다음과 같습니다.
> -   `15.3 > 4.5`  -> 비트 할당: `1`
> -   `-20.1 > 4.5` -> 비트 할당: `0`
> -   `5.5 > 4.5`  -> 비트 할당: `1`
> -   `30.9 > 4.5` -> 비트 할당: `1`
> -   `-2.0 > 4.5` -> 비트 할당: `0`
>
> 이 과정을 63번 반복하면, `10110...` 과 같은 63자리 이진 문자열이 만들어집니다.

-   **요약:** 이 과정은 63비트의 **이진 문자열**을 생성하며, 이것이 최종적인 이미지의 **지각 해시**가 됩니다. 이 해시는 이미지의 저주파수 구조를 고유하게 나타내는 핑거프린트 역할을 합니다.

#### **해밍 거리(Hamming Distance)를 이용한 검증:**
**테스트 이미지**의 pHash ($H_{\text{test}}$)와 **참조 이미지**의 pHash ($H_{\text{ref}}$) 사이의 **해밍 거리(Hamming distance)** $d_H$를 계산합니다.
$$d_H(H_{\text{test}}, H_{\text{ref}}) = \sum_{i=1}^{63} \left| h_{\text{test}, i} - h_{\text{ref}, i} \right|$$- 이 해밍 거리가 특정 임계값 $\tau_p$보다 작거나 같으면 검증을 통과합니다.

$$d_H(H_{\text{test}}, H_{\text{ref}}) \leq \tau_p$$

- 거리가 작을수록 두 이미지는 **유사**하거나 **일치**하는 것으로 간주합니다.

#### **pHash 요약:**

- **pHash**는 이미지의 **저주파수 성분**을 기반으로 **고유한 핑거프린트**를 생성합니다.
- **크기 조정**이나 **압축**과 같은 **사소한 변경에는 강하지만**, 이미지의 **전체적인 구조**가 바뀌면 값도 변경됩니다.
- **해밍 거리**는 두 해시 값을 비교하여 이미지의 유사성을 검증하는 데 사용됩니다.

#### **pHash의 활용 분야:**
- 중복 이미지 탐지
- 유사도 비교를 위한 이미지 대조
- 지각적 유사성에 기반한 효율적인 이미지 인덱싱

### 2. 고주파 그리드(HFG) 강도

이 지표는 복사 시 쉽게 손상되는 **깨지기 쉬운(Fragile) 워터마크**를 이미지에 삽입하고, 그 손상 여부를 측정하여 진위를 판별하는 기술입니다.

#### 워터마크 삽입 원리
원본 "보안" 이미지에는 사람의 눈에는 보이지 않는 미세한 격자(Grid) 패턴이 숨겨져 있습니다. 이 패턴은 아래와 같은 방식으로 만들어집니다.

1.  이미지 전체에 일정한 간격($s$)으로 '그리드 포인트'를 설정합니다.
2.  이 그리드 포인트에 해당하는 픽셀들의 밝기 값을 주변 픽셀보다 **아주 약간만 높입니다.** (예: 원래 밝기가 150이었다면 155로 변경)

이 미세한 차이는 일반적인 시각으로는 인지할 수 없지만, 인쇄 후 스캔하거나 화면을 촬영하는 등 복사 과정에 필연적으로 발생하는 **흐림(Blur) 현상**에 의해 쉽게 파괴됩니다.

#### 검증 원리 및 예시
검증 시에는 이미지에서 그리드 포인트들의 평균 밝기와, 그리드가 아닌 나머지 픽셀들의 평균 밝기를 비교하여 그 차이를 계산합니다.

> **[ 간단한 4x4 이미지의 HFG 강도 계산 예시 ]**
>
> 이해를 돕기 위해, 간격을 2($s=2$)로 설정한 4x4 이미지 블록이 있다고 가정해 보겠습니다. 그리드 포인트는 (0,0), (0,2), (2,0), (2,2) 위치가 됩니다.
>
> **1. 정품 이미지의 경우**
>
> 그리드 포인트의 밝기(110)가 주변(100)보다 약간 더 높게 유지됩니다.
>
> **입력 이미지 $I_{정품}$**
> 
> $$\begin{bmatrix}\mathbf{110} & 100 & \mathbf{110} & 100 \\\\\ 100 & 100 & 100 & 100 \\\\\mathbf{110} & 100 & \mathbf{110} & 100 \\\\\ 100 & 100 & 100 & 100\end{bmatrix}$$
>
> -   **그리드 픽셀 평균($\mu_G$):** `(110 + 110 + 110 + 110) / 4 = 110`
> -   **비-그리드 픽셀 평균($\mu_{\neg G}$):** `(100 * 12) / 12 = 100`
> -   **HFG 강도($S_{HFG}$):** `110 - 100 =` **`10`**
>
> **2. 위조(복사) 이미지의 경우**
>
> 인쇄-스캔 과정의 흐림 현상으로 인해 그리드 포인트의 높은 밝기 값이 주변으로 퍼져나가면서 전체적으로 평준화됩니다.
>
> **입력 이미지 $I_{위조}$**
> 
> $$\begin{bmatrix}\mathbf{102} & 101 & \mathbf{102} & 101 \\\\\ 101 & 101 & 101 & 101 \\\\\mathbf{102} & 101 & \mathbf{102} & 101 \\\\\ 101 & 101 & 101 & 101\end{bmatrix}$$
>
> -   **그리드 픽셀 평균($\mu_G$):** `(102 + 102 + 102 + 102) / 4 = 102`
> -   **비-그리드 픽셀 평균($\mu_{\neg G}$):** `(101 * 12) / 12 = 101`
> -   **HFG 강도($S_{HFG}$):** `102 - 101 =` **`1`**

**검증:**
예시에서 보듯, 정품 이미지의 HFG 강도(10)는 위조품(1)에 비해 월등히 높습니다. 이 원리를 이용해 측정된 강도 $S_{HFG}$가 미리 설정된 최소 임계값 $\tau_h$보다 크거나 같으면 정품으로 판별합니다.

$$S_{HFG}(I_{test}) \ge \tau_h$$

만약 임계값 $\tau_h$가 `5`라면, 정품 이미지는 통과하고 위조 이미지는 실패하게 됩니다.

### 3. 주파수 피크 비율(FPR)

이 기술은 이미지에 특정 주파수를 가진 '비밀 신호'를 숨겨두고, 그 신호의 선명도를 측정하여 진위를 판별하는 방식입니다. 라디오에 비유하자면, 이미지에 우리만 아는 특정 주파수(`k` MHz)로 비밀 라디오 방송을 송출한 뒤, 스캔된 이미지에서 그 방송이 여전히 선명하게 들리는지 확인하는 것과 같습니다.

#### 워터마크 삽입 원리
원본 이미지의 각 행(또는 열)에 걸쳐, 특정 주파수 $k$를 갖는 주기적인 신호(사인파)를 매우 미세하게 추가합니다. 이로 인해 이미지에는 육안으로 식별하기 어려운, 가로 또는 세로 방향의 희미한 밝기 파동이 생기게 됩니다. 이 섬세한 패턴은 이미지 압축, 리샘플링, 인쇄-스캔 과정에서 발생하는 데이터 손실에 매우 취약합니다.

#### 검증 원리 및 예시
검증 시에는 이미지에서 한 줄의 픽셀 데이터(신호)를 추출하고, **푸리에 변환(FFT)**을 통해 주파수 성분을 분석합니다.

1.  **신호 추출 및 푸리에 변환 (FFT)**

    이미지의 중간에 있는 한 줄의 픽셀 밝기 값($r(x)$)을 이산 신호 $x_n$으로 간주하고, 여기에 **이산 푸리에 변환(DFT)**을 적용합니다. (FFT는 이 DFT를 빠르게 계산하는 효율적인 알고리즘의 이름입니다.)

    **[ 1D 이산 푸리에 변환(DFT) 공식 ]**

    $$X_k = \sum_{n=0}^{N-1} x_n \cdot e^{-i \frac{2\pi}{N} kn}$$

    이 공식은 입력 신호($x_n$)가 각각의 주파수 성분($k$)을 얼마나 포함하고 있는지를 계산합니다. 결과값 $X_k$는 복소수(complex number)이며, 우리는 이 값의 **크기(Magnitude)**, 즉 $M(k) = |X_k|$에만 관심이 있습니다. 이 크기가 바로 해당 주파수의 '신호 세기'를 나타냅니다.

3.  **정품 이미지의 스펙트럼**

    정품 이미지에는 우리가 심어둔 주파수 $k$의 사인파가 선명하게 남아있으므로, 주파수 스펙트럼에서 해당 지점의 **신호가 매우 강력한 피크(Peak)**를 형성합니다.

    -   목표 주파수($k$)에서의 신호 크기: $M(k) = 150$
    -   주변 배경 주파수의 평균 크기: $\mu_{bg} = 10$
    -   **피크 비율($R_{FP}$):** $M(k) / \mu_{bg} = 150 / 10 =$ **`15`**

4.  **위조(복사) 이미지의 스펙트럼**

    복사 과정에서 미세한 사인파 패턴이 손상되면서, 강력했던 피크는 뭉개지고 약해져 주변의 노이즈와 비슷해집니다.

    -   목표 주파수($k$)에서의 신호 크기: $M(k) = 25$
    -   주변 배경 주파수의 평균 크기: $\mu_{bg} = 10$
    -   **피크 비율($R_{FP}$):** $M(k) / \mu_{bg} = 25 / 10 =$ **`2.5`**

**검증:**
이처럼 정품 이미지의 피크 비율(15)은 위조품(2.5)보다 훨씬 높게 나타납니다. 이 비율($R_{FP}$)이 미리 정해진 임계값 $\tau_f$보다 크거나 같으면, '비밀 방송'이 선명하게 수신된 것으로 판단하여 정품으로 인증합니다.

$$R_{FP} = \frac{M(k)}{\mu_{bg}}$$

$$R_{FP}(I_{test}) \ge \tau_f$$

만약 임계값 $\tau_f$가 `7`이라면, 정품 이미지는 통과하지만 위조 이미지는 통과하지 못합니다.

**검증:**
이처럼 정품 이미지의 피크 비율(15)은 위조품(2.5)보다 훨씬 높게 나타납니다. 이 비율($R_{FP}$)이 미리 정해진 임계값 $\tau_f$보다 크거나 같으면, '비밀 방송'이 선명하게 수신된 것으로 판단하여 정품으로 인증합니다.

$$R_{FP} = \frac{M(k)}{\mu_{bg}}$$

$$R_{FP}(I_{test}) \ge \tau_f$$

만약 임계값 $\tau_f$가 `7`이라면, 정품 이미지는 통과하지만 위조 이미지는 통과하지 못합니다.


## 결과 및 주요 발견

### 1. 디지털 PNG-PNG 비교에서의 성공

**이 방법은 순전히 디지털 맥락에서 매우 성공적이었습니다.** 이를 검증하기 위해 `src/test_verify.py` 스크립트를 사용할 수 있으며, 이 스크립트는 원래 신호 처리 로직을 사용하여 깨지기 쉬운 워터마크를 확인합니다.

원본 디지털 **보안** 이미지에 대해 테스트했을 때 스크립트는 모든 이미지를 정품으로 정확하게 식별합니다:

```
$ python src/test_verify.py --mode verify --input_dir "True_data/secured" --meta "config/signatures.json"

ecoqcode (1).png: GENUINE  |  detail={'hamming': 0, 'hf_strength': 0.573, 'fft_peak_ratio': 26.27, ...}
ecoqcode (10).png: GENUINE  |  detail={'hamming': 0, 'hf_strength': 0.540, 'fft_peak_ratio': 10.66, ...}
ecoqcode (11).png: GENUINE  |  detail={'hamming': 0, 'hf_strength': 0.568, 'fft_peak_ratio': 3.04, ...}
...
```

반대로 **시뮬레이션된 사본**(인쇄 및 스캔으로 인한 저하를 모방)에 대해 테스트했을 때 스크립트는 모든 사본을 가짜로 정확하게 식별합니다:

```
$ python src/test_verify.py --mode verify --input_dir "False_data/simulated_copies" --meta "config/signatures.json"

ecoqcode (1)_copy1.png: COPY/ALTERED  |  detail={'hamming': 4, 'hf_strength': 0.127, 'fft_peak_ratio': 3.46, ...}
ecoqcode (1)_copy2.png: COPY/ALTERED  |  detail={'hamming': 0, 'hf_strength': 0.052, 'fft_peak_ratio': 12.74, ...}
ecoqcode (1)_copy3.png: COPY/ALTERED  |  detail={'hamming': 4, 'hf_strength': 0.075, 'fft_peak_ratio': 1.60, ...}
...
```

이는 환경 변수가 제거된 순수한 디지털 영역에서 깨지기 쉬운 워터마크를 사용하는 핵심 원칙이 유효함을 확인시켜 줍니다. 육안으로는 두 PNG 파일 세트가 거의 동일하게 보입니다.

### 2. 물리적 매체의 과제

프로젝트의 주요 과제는 디지털 파일에서 실제 응용 프로그램으로 이동할 때 나타났습니다. 스마트폰 카메라(iPhone 13 Pro)를 사용하여 인쇄된 QR 코드를 확인하려고 할 때 결과가 일관되지 않았습니다.

**불일치 이유:** 검증 로직이 너무 민감하여 매체 자체의 물리적 특성에 영향을 받았습니다. 추론 결과는 다음에 따라 변경되었습니다:
*   용지의 질감, 광택 및 색상.
*   주변 조명 조건.
*   카메라의 특정 각도 및 거리.

이는 시스템이 안정적으로 작동하려면 **고도로 통제된 환경**이 필요함을 의미합니다. 예를 들어, QR 코드가 항상 통제된 조명 아래 특정 표준화된 유형의 용지에 인쇄되는 경우 검증이 가능합니다. 이는 방법의 보편적인 적용 가능성을 제한하지만, 인쇄 매체를 표준화할 수 있는 높은 보안 시나리오에 대한 실행 가능성을 증명합니다.

### 3. 사례 연구: 디스플레이에서 iPhone 13 Pro 카메라 추론

실제 검증의 과제를 추가로 조사하기 위해 특정 테스트를 수행했습니다. 정품 암호화된 QR 코드와 알려진 위조 QR 코드를 화면에 표시한 다음 iPhone 13 Pro를 사용하여 스캔했습니다.

**테스트 1: 정품 QR 코드 스캔**

![iPhone 카메라 테스트 - 정품](config/Result(Web_predict).jpg)

*   **결과:**
    *   `pHash Dist : 12 (Max : 18) -> OK`
    *   `FFT Ratio : 8.589 (Min : 1.5) -> OK`
    *   `HF Strength: -0.365 (Min: 0.15) -> NO`

**테스트 2: 위조 QR 코드 스캔**

![iPhone 카메라 테스트 - 가짜](config/Result(Fake).jpg)

*   **결과:** 위조된 코드는 거의 동일한 결과를 생성했으며, `pHash Dist` 및 `FFT Ratio` 검사를 통과했지만 `HF Strength`는 실패했습니다.

**분석:**
중요한 통찰력은 이 두 테스트를 비교하는 데서 나옵니다. 언뜻 보기에 정품 테스트는 세 가지 메트릭 중 두 가지를 통과했기 때문에 부분적으로 성공한 것처럼 보입니다. 그러나 알려진 위조품이 *또한* 정확히 동일한 두 메트릭을 통과한다는 사실은 이 맥락에서 검증에 쓸모가 없게 만듭니다. `HF Strength` 메트릭은 둘 다 실패했지만, 둘을 구별할 수 없으므로 신뢰할 수 없는 지표이기도 합니다.

**결론:**
이 비교 테스트는 디스플레이에서 확인할 때 현재 로직이 정품 코드와 위조 코드를 구별할 수 없음을 증명합니다. 화면의 디스플레이 속성(픽셀, 빛 등)은 스캔되는 *모든* QR 코드에 대해 일관된 아티팩트 세트를 생성하여 `pHash` 및 `FFT` 검사에서 위양성을 유발합니다. 이는 **화면에서 검증하는 것이 현재 이 방법으로는 불가능하다**는 결론을 강화합니다.

### 3. 접근 방식의 진화: 신호 처리에서 딥 러닝으로

초기 테스트, 특히 화면에서 스캔하는 것과 관련된 테스트는 신호 처리 방법이 너무 깨지기 쉽고 환경 소음에 취약하다는 것을 보여주었습니다. 통제된 디지털 환경에서는 작동했지만 더 현실적인 시나리오에서는 신뢰할 수 있는 결과를 제공하지 못했습니다.

**인쇄물에 대한 초기 테스트는 엇갈린 결과를 낳았습니다.** 아래와 같이 정품 인쇄 QR 코드는 정확하게 식별되었습니다:

![정품 QR 코드 검증](config/Result(real).jpg)

그러나 고품질 가짜(A4 용지 사본)로 테스트할 때 시스템은 어려움을 겪었습니다. 종종 가짜로 식별했지만 때로는 정품으로 잘못 분류하여 방법의 신뢰성을 떨어뜨렸습니다.

![가짜 QR 코드 테스트 1](config/Result(Fake_A4)_1.jpg)
![가짜 QR 코드 테스트 2](config/Result(Fake_A4)_2.jpg)
*캡션: 종종 가짜로 감지되었지만 이러한 고품질 사본은 때때로 정품으로 잘못 분류되었습니다.*

이러한 한계를 극복하고 더 강력한 검증 시스템을 구축하기 위해 프로젝트는 **컨볼루션 신경망(CNN)을 사용하는 딥 러닝 접근 방식**으로 전환했습니다. 새로운 목표는 단일의 깨지기 쉬운 내장 신호에 의존하는 대신, 정품 QR 코드와 가짜 QR 코드를 구별하는 시각적 특징을 학습하도록 모델을 훈련하는 것이었습니다.

#### 3.1 CNN 모델을 위한 데이터 수집

현실적인 변형에 초점을 맞춰 모델을 훈련시키기 위해 포괄적인 데이터 세트를 수집했습니다.

**정품 데이터(원본 155개):**
*   **고품질(62개 이미지):** 보안 QR 코드를 인쇄하여 iPhone 13 Pro로 촬영했습니다.
    *   어두운 환경에서 31개 이미지.
    *   밝은 자연광에서 31개 이미지.
*   **저품질(93개 이미지):** 견고성을 향상시키기 위해 멀리서 추가 이미지를 캡처하여 해상도를 낮췄습니다.
    *   어두운 환경에서 31개 이미지.
    *   밝은 형광등 아래에서 31개 이미지.
    *   밝은 자연광에서 31개 이미지.

**가짜 데이터(원본 124개):**
*   **1세대 사본(62개 이미지):** 원본 인쇄 QR을 한 번 복사했습니다.
*   **2세대 사본(62개 이미지):** 1세대 사본을 다시 복사하여 추가적인 저하를 시뮬레이션했습니다.

#### 3.2 데이터 증강

더 크고 다양한 훈련 세트를 만들기 위해 모든 279개 원본 이미지(정품 155개 + 가짜 124개)를 **10배로 증강**했습니다. 증강에는 다음과 같은 무작위 변형이 포함되었습니다:
*   노이즈
*   밝기

그 결과 훈련 및 검증을 위한 총 2,790개의 이미지 데이터 세트가 생성되었습니다.

#### 3.3 모델 훈련 및 성능

증강된 데이터 세트에서 CNN 모델을 훈련했습니다. 훈련 과정은 매우 유망한 결과를 낳았으며 **99% 이상의 검증 정확도**를 달성했습니다. 이는 모델이 정품 및 가짜 QR 코드 이미지를 효과적으로 구별하는 방법을 학습했음을 나타냅니다.

#### 3.3.1 모델 아키텍처

이 모델은 사전 훈련된 잘 알려진 아키텍처를 기반으로 사용하여 **전이 학습**을 활용합니다. 이 접근 방식을 통해 모델은 대규모 데이터 세트(ImageNet)에서 학습한 강력한 특징 추출 기능을 활용할 수 있습니다.

아키텍처는 두 가지 주요 부분으로 구성됩니다:

1.  **기본 모델:** `tf.keras.applications`에서 제공하는 `MobileNetV2`.
    *   `imagenet` 가중치로 초기화됩니다.
    *   전체 기본 모델은 "고정"(`trainable = False`)되어 훈련 중에 가중치가 업데이트되지 않습니다. 고정된 특징 추출기로 작동합니다.

2.  **사용자 정의 분류기 헤드:** 특정 이진 분류 작업(정품 대 가짜)에 맞게 `MobileNetV2` 기반 위에 새로운 레이어 세트가 추가되었습니다.
    *   `GlobalAveragePooling2D`: 기본 모델의 특징의 공간 차원을 줄입니다.
    *   `Dropout (rate=0.2)`: 과적합을 방지하기 위한 정규화 기술입니다.
    *   `Dense (1, activation='sigmoid')`: 0과 1 사이의 확률 점수를 출력하는 시그모이드 활성화 함수가 있는 단일 뉴런의 최종 출력 레이어입니다.

모델은 이진 분류 작업에 대한 표준 선택인 `Adam` 옵티마이저(학습률 0.001) 및 `BinaryCrossentropy` 손실 함수로 컴파일되었습니다.

**모델 요약:**

```
Model: "functional"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 input_layer (InputLayer)    [(None, 224, 224, 3)]     0

 mobilenetv2_1.00_224        (None, 7, 7, 1280)        2,257,984
 (Functional)

 global_average_pooling2d    (None, 1280)              0
 (GlobalAveragePooling2D)

 dropout (Dropout)           (None, 1280)              0

 dense (Dense)               (None, 1)                 1,281
=================================================================
 Total params: 2,259,265
 Trainable params: 1,281
 Non-trainable params: 2,257,984
```
*(참고: 전처리 레이어는 모델의 일부이지만 간결성을 위해 이 요약에서 생략되었습니다.)*

정확도 및 손실 곡선을 포함한 자세한 훈련 기록은 다음과:

![모델 훈련 기록](results/training_history.png)

#### 3.4 검증 및 한계 분석

성공적인 훈련 후, 모델의 성능은 `src/visual_test.py` 스크립트를 사용하여 다양한 데이터 범주에서 어떻게 수행되는지 평가되었습니다.

아래 이미지에 표시된 결과는 모델의 로직에 치명적인 결함이 있음을 보여주었습니다.

![시각적 테스트 결과](config/Test_result.png)

**분석:**
*   **성공:** 이 모델은 정품 인쇄 QR 코드 사진(`Augmented (True)`)과 간단한 종이 사본 사진(`Augmented (False)`)을 구별하는 데 매우 효과적입니다.
*   **실패:** 이 모델은 모든 디지털로 변경된 가짜(`Simulated Copies (Expected: False)`)를 "True"로 잘못 분류합니다.

이 결과는 모델이 우리가 내장한 *특정* 깨지기 쉬운 워터마크 패턴을 학습하지 않았음을 강력하게 시사합니다. 대신, 인쇄물 사진과 사본 사진을 구별하는 더 일반적인 특징(예: 질감, 모아레 패턴, 미묘한 조명 변경)을 기반으로 예측하는 것으로 보입니다. 본질적으로, *올바른* 패턴이 아닌 *모든* 인쇄와 유사한 패턴의 존재를 감지하고 있습니다.

### 4. 하이브리드 모델을 사용한 추가 실험

초기 분석 결과 CNN 모델이 특정 워터마크를 학습하지 않는 것으로 나타났습니다. 다음 논리적 단계는 워터마크의 정량적 특징을 보다 직접적으로 분석할 수 있는 모델을 만드는 것이었습니다.

#### 4.1 실험 1: 디지털 데이터에 대한 하이브리드 모델
모델이 특정 패턴을 학습하도록 강제하기 위해 하이브리드 접근 방식이 개발되었습니다. 이 다중 입력 모델은 이미지 데이터뿐만 아니라 각 디지털 이미지와 관련된 세 가지 서명 값(`phash`, `hf_strength`, `fft_peak_ratio`)에 대해서도 훈련되었습니다. 모델은 `secured`(True) 및 `simulated_copies`(False) 데이터 세트에서 훈련되었습니다. 아래 그림과 같이 훈련 자체는 매우 성공적이어서 거의 완벽에 가까운 검증 정확도를 달성했습니다.

![디지털 하이브리드 모델 훈련 기록](results/training_history_multi_input.png)

하지만, 훌륭한 훈련 결과에도 불구하고, 시각적 테스트 결과 실제 이미지(카메라로 찍은 사진)에서는 모델이 완전히 실패하여 모두 `false`로 분류했습니다. 이는 깨지기 쉬운 워터마크가 인쇄 및 스캔 프로세스에 의해 파괴되었음을 확인시켜 주었습니다.

![디지털 훈련 하이브리드 모델의 시각적 테스트 결과](results/visual_test_results_multi_input.png)

#### 4.2 실험 2: 실제 데이터에 대한 하이브리드 모델
카메라 이미지에 대한 실패를 감안할 때, 다음 실험은 보다 현실적인 데이터 세트(`augmented_data`)에서 동일한 하이브리드 모델을 훈련하는 것이었습니다. 그러나 결과는 대체로 동일했습니다. 모델은 원시 디지털 QR 코드를 올바르게 분류하는 방법을 배웠지만, 정품 인쇄물 사진과 사본 사진 간의 의미 있는 구별을 찾지 못했습니다.

![증강 훈련 하이브리드 모델의 시각적 테스트 결과](results/visual_test_results_augmented.png)

이는 이 특정 깨지기 쉬운 워터마킹 방법이 하이브리드 모델로 분석하더라도 물리적 인쇄-스캔-검증 워크플로에 충분히 강력하지 않다는 결론으로 이어졌습니다.

### 5. CNN 모델 및 크기 종속성 분석을 사용한 최종 검증

주요 목표는 카메라 기반 추론이고 하이브리드 모델이 실제 데이터에서 만족스러운 결과를 내지 못했기 때문에, 가장 유망해 보였던 원래의 CNN 전용 모델로 돌아갔습니다. 웹 카메라 응용 프로그램을 사용하여 실제 성능을 검증하기 위해 라이브 테스트를 수행했습니다.

#### 5.1 표준 크기 QR 코드에 대한 성공적인 검증
결과는 긍정적이었습니다. A4 용지에 인쇄된 표준 크기 QR 코드로 테스트했을 때, 모델은 정품 인쇄물과 사본을 성공적으로 구별할 수 있었습니다.

*   **정품:** 원본 소스(`Test_origin.jpg`)에서 인쇄된 QR 코드가 GENUINE으로 올바르게 식별되었습니다.
*   **사본:** 1세대 및 2세대 사본(`Test_Onecopy.jpg`, `Test_Doublecopy.jpg`)이 위조품으로 올바르게 식별되었습니다.

이는 모델이 이러한 조건에서 복사로 인해 발생하는 워터마크 패턴의 저하를 식별할 수 있음을 보여줍니다.

| 정품 원본 | 1세대 사본 | 2세대 사본 |
| :---: | :---: | :---: |
| ![정품 검증](results/Test_origin.jpg) | ![1세대 사본 검증](results/Test_Onecopy.jpg) | ![2세대 사본 검증](results/Test_Doublecopy.jpg) |

#### 5.2 크기 종속성 및 대형 QR 코드에서의 실패
더 큰 크기의 QR 코드로 테스트할 때 중요한 한계가 발견되었습니다. 큰 QR을 인쇄한 다음 복사했을 때, 모델은 사본을 GENUINE으로 잘못 분류했습니다.

아래 이미지(`Test_BigQR.jpg`)는 웹 응용 프로그램의 실시간 추론 결과를 보여줍니다. 스캔되는 QR 코드는 **1세대 사본**이지만 모델은 이를 정품으로 잘못 식별합니다. 이것은 바람직하지 않은 결과입니다.

![대형 복사 QR 검증 실패](results/Test_BigQR.jpg)

**분석:**
QR 코드의 물리적 크기는 중요한 변수입니다. 더 큰 QR 코드를 복사하면 내장된 깨지기 쉬운 패턴도 확대되어 더 강력해지고 복사 과정에서 파괴될 가능성이 줄어듭니다.

*   **대형 사본**에서는 상당수의 워터마크 패턴이 시각적으로 식별 가능하게 남아있어 모델이 이를 정품으로 분류하는 이유입니다.
*   **소형 사본**에서는 이러한 패턴이 거의 완전히 제거되거나 식별할 수 없는 점으로 축소되어 모델이 이를 가짜로 올바르게 식별할 수 있습니다.

#### 5.3 최종 결론
CNN 전용 모델은 표준 A4 크기 용지에서 QR 코드를 확인하는 데 효과적입니다. 이 규모에서는 정품 인쇄물과 사본을 안정적으로 구별할 수 있습니다. 그러나 모델의 유효성은 물리적 인쇄 크기에 크게 의존합니다. 워터마크 패턴이 복사 과정을 견뎌내는 더 큰 QR 코드에는 효과적이지 않습니다. 이는 현재 시스템이 실행 가능하지만 안정적인 검증을 위해 통제된 인쇄 크기가 필요함을 의미합니다.

## 향후 발전 가능성

이 연구의 궁극적인 목표는 다음과 같이 상충되지만 필수적인 두 가지 속성을 모두 만족하는 워터마크를 개발하는 것입니다.
1.  **완벽한 강인성:** 원본 디지털 소스에서 인쇄된 후에도 일반 카메라로 일관되게 탐지될 수 있는 워터마크.
2.  **완벽한 취약성:** 정품 인쇄물이 복사될 때 완전히 파괴되거나 인식 불가능할 정도로 변경되는 워터마크.

본질적으로, 이 과제는 원본 QR 코드에 내장된 고유의 해시 워터마크를 안정적으로 인식하면서도, 복제 시에는 확실하게 파괴되는 것을 보장하는 기술을 개발하는 것입니다.

이는 여전히 활발하고 도전적인 연구 분야로 남아있습니다. 시간 및 자원의 제약으로 인해 개인이 이러한 시스템을 개발하는 것은 상당한 노력이 필요한 일이지만, 저희는 이것이 달성 가능한 기술이라고 믿습니다. 고급 신호 처리, 새로운 소재 또는 최적의 패턴을 생성하도록 훈련된 머신러닝 모델에 대한 추가 연구를 통해 이 가능성을 열 수 있을 것입니다.

## 이 프로젝트 사용 방법

### 전제 조건
*   Python 3.x
*   필수 Python 라이브러리(예: OpenCV, NumPy, scikit-image). pip를 통해 설치할 수 있습니다:
    ```bash
    pip install opencv-python numpy scikit-image
    ```
*   웹 기반 검증용: `Flask` 및 `ngrok`.
    ```bash
    pip install Flask
    ```

### 사용법 1: PNG 파일 확인

로컬 QR 코드 이미지 파일을 확인하려면 터미널에서 `test_verify.py` 스크립트를 실행할 수 있습니다.

**명령:**
```bash
python test_verify.py --image "path/to/your/qrcode.png"
```
스크립트는 이미지를 분석하고 파일이 정품인지 위조품인지 여부를 출력합니다.

### 사용법 2: 웹 기반 카메라 검증(실험적)

이 설정을 사용하면 컴퓨터 또는 휴대폰의 카메라를 사용하여 실시간 검증을 시도할 수 있습니다.

**참고:** 위에서 언급했듯이 이 방법은 실험적이며 실패할 가능성이 높지만 의도된 실제 응용 프로그램을 보여줍니다.

**1단계: 로컬 웹 서버 시작**

웹 응용 프로그램은 `OCR/` 디렉토리에 있습니다. Flask 서버를 시작합니다. 포트 8000에서 실행되는 것으로 가정합니다.

```bash
cd OCR
python app.py
```

**2단계: ngrok으로 서버 노출**

최신 웹 브라우저는 카메라 하드웨어에 액세스하려면 보안 `https://` 연결이 필요합니다. `ngrok`은 로컬 서버에 대한 보안 공용 URL을 생성하는 도구입니다.

**새 터미널 창**에서 다음 명령을 실행합니다:

```bash
ngrok http 8000
```

**3단계: 응용 프로그램 액세스**

`ngrok`은 공개 HTTPS URL(예: `https://random-string.ngrok.io`)을 제공합니다. 스캔에 사용할 장치(예: iPhone)의 웹 브라우저에서 이 URL을 엽니다. 그런 다음 사이트에 카메라 액세스 권한을 부여하고 QR 코드를 확인해 볼 수 있습니다.

```
